\section{Iteration \#1 -- Evaluation Framework, Baselines and the Pyramid Tree}

The first iteration was chosen to be two weeks long, instead of just one. This was to accommodate the extra work that would need to be done initially to lay the foundations that would be used to implement and evaluate the implementations. The objectives for this iteration were:
\begin{itemize}
	\item Design and implement a standard framework for evaluating index structures in C++
	\item Implement evaluation baselines (Sequential Scan and Octree)
	\item Incorporate the School's implementation of the Pyramid Tree into framework
	\item Analyse performance of two baselines and the Pyramid Tree, evaluating their performance
\end{itemize}

\subsection{Evaluation Framework}

The evaluation framework implemented in the first week of this iteration was created to define the standard data used across the index structures, provide a way of loading point datasets and operation lists and feeding them to index structures. There are three core modules of the framework:

\begin{wrapfigure}[12]{r}{0.5\textwidth}
	\vspace{-40pt}
	\begin{center}
		\includegraphics[scale=0.4]{figures/evaluation_framework.pdf}
	\end{center}
	\vspace{-20pt}
	\caption{Modules of Evaluation Framework}
	\label{fig:evaluation-framework}
\end{wrapfigure}

\begin{itemize}
	\item \texttt{data} -- library that contains standard data types used throughout framework and index structures, as well as dataset and test operation generators/loaders
	\item \texttt{index\_structure} -- library that contains all the index structures implemented throughout the project
	\item \texttt{evaluator} -- executable program that takes the index structures, operation lists and other options from the command line and runs a set of automated performance tests that produces timings and profiling (CPU and heap) information
\end{itemize}

The \texttt{evaluator} executable facilitates fast evaluation by allowing multiple index structures to be tested at once, using multiple tests operation lists (as described in Chapter \ref{chap:evaluation-outline}) at once. It stores timings in text files which are fed into bash and Gnuplot scripts to generate plots, which can be understood and incorporated into the report with ease. Figure \ref{fig:evaluation-framework} illustrates the modules of the framework, showing how user performing the performance evaluation only directly interacts with the \texttt{evaluator} executable.

The framework was created because performance analysis would be done very frequently, multiple times per iteration. Manually timing and profiling the code each time is time-consuming and error-prone. Putting more effort initially into creating a system that allows large sets of operations and index structures to be tested at once may save a significant amount of time , especially as many of these performance test are long and must be run multiple times to get averages.

Every index structure defined in the \texttt{index\_structures} module implement the \texttt{IndexStructure} interface, which has the following methods:
\begin{itemize}
	\item \texttt{loadPoints} -- bulk load a collection of points into structure
	\item \texttt{clear} -- remove all points from structure
	\item \texttt{insert} -- insert point into structure (if it's not already stored, see assumption (4) in Section \ref{sec:core-assumptions})
	\item \texttt{remove} -- remove point from structure
	\item \texttt{update} -- modify value of a specific point stored in the structure
	\item \texttt{pointExists} -- equivalent to a point query
\end{itemize}

\subsection{Baseline Implementations}
 
Sequential scan was implemented using the C++ container \texttt{std::vector}, a dynamically resizeable array. Points insertion is $O(1)$ as they are added to the end of the vector and deleting points results in a standard array deletion, making it an $O(n)$ operation. Point queries are performed in $O(n)$ time, as the query iterates through the array sequentially until the given point is found or the end of the array is reached.

The octree variant implemented as a baseline is a bucket PR octree. This means the structure partitions the underlying data space into uniformly sized boxes, without using the points as pivots (unlike point quadtrees or kd-trees). It is a bucket octree because \textit{multiple} points can be stored in a single leaf node. The octree dynamically decomposes and composes spatial regions based on its current contents. When the number of points in a leaf node exceeds a certain number, say $M$, then the region represented by the leaf is sub-divided, creating $2^d$ children. The $M + 1$ points are then scattered across the children. Therefore, regions of space that contain more points are decomposed more and sparse regions of space have less granularity, meaning less nodes and memory overhead.

When a point is deleted from a leaf, the contents of the leaf and all of its siblings are checked. If all of these nodes are empty, they are removed and the sub-regions are combined into the original region again. If the now collapsed parent and all of its siblings are empty, then they are collapsed into their parent. This is repeatedly recursively until a parent is reached whose children contain at least one point.

\subsection{Pyramid Tree}

As described in Section \ref{sec:pyramid-tree}, the Pyramid tree reduces multi-dimensional points to one dimension, which can then be used in a one-dimensional index structure. The School of Computing have an existing implementation of the Pyramid tree, written by TODO. While Berchtold et al. in \cite{pyramid-tree} used a B${}^{+}$-tree as the underlying 1D structure, this implementation uses a hash map (specifically \texttt{boost::unordered\_map}). All the points are stored in a single \texttt{std::vector}. Each point is hashed to an integer representation which acts as the key to a bucket stored in the hash map. A bucket is
 a \texttt{std::vector} which contains indices to points in the large point array.
 
Simple optimisations were initially made to the original implementation. The original implementation passed many heap allocated structures by-value, resulting in excessive copies and more time being spent allocating memory and copying data. These copies were not necessary and were removed where possible by passing the data by-reference.

The original Pyramid tree implementation did not provide \texttt{delete} and \texttt{update} operations. Therefore, a \texttt{delete} procedure was added to the implementation. To delete a point $p$, the point is first hashed and the bucket containing the point is found. The index pointing to $p$ in the bucket is removed from the bucket, but the actual point itself is not removed the point array. In other words, the memory is never released until the whole structure is deleted. This makes the structure useful for batch computation because it can be discarded straight after a task, releasing all allocated memory then. However, if the structure is used as part of a long-running process then this is not suitable because there is the potential to run out of memory. This will be referred to as the \textbf{Batch Pyramid Tree} for the rest of this document.

Therefore, a variant of this structure was implemented, which shall be referred to as the \textbf{Defragmented Pyramid Tree}. When a point's index is deleted from a bucket, the element at the index is marked for deletion from the array at a later time. If the number of marked elements exceeds a certain number $R$, then the $R + 1$ marked elements are erased from the vector (i.e. memory is released). The indices in each bucket are then updated to point to the correct element in the modified array. Even though \texttt{delete} is normally a constant time operation, the worst case is $O(n^2)$ because of this defragmentation procedure.

\subsection{Compiler Optimisation}

TODO: compiler optimisation -- why I decided to not use -O3, despite it making CPU profiling unclear

TODO: optmisations 

\subsection{Performance Analysis}

For this analysis, the three synthetic datasets described in Section \ref{sec:TODO} were used, each having $10000$ points and varying dimensions. Timestep 100 of the astrophysics turbulence simulation was also used at an eighth of the resolution, producing a uniformly sampled $75 \times 31 \times 31$ grid with $72075$ points.th

TODO: introduced tables and figures

TODO: CPU and heap profiling

TODO: show all the graphs, tables, etc.

\begin{table}
	\centering
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
		\hline
		\textbf{Structure} & \textbf{1D} & \textbf{2D} & \textbf{3D} & \textbf{5D} & \textbf{10D} & \textbf{50D} & \textbf{100D} & \textbf{200D} \\
		\hline
		\textbf{Sequential Scan} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
		\textbf{Octree} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
		\textbf{Defragmented Pyramid Tree} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
		\textbf{Batch Pyramid Tree} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
		\hline
	\end{tabular}
	\caption{Execution Time of Structures for Uniform Randomly Generated Points with \texttt{-O1} Compiler Flag}
	\label{tab:perf1-randuniform-o1}
\end{table}

\begin{table}
	\centering
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
		\hline
		\textbf{Structure} & \textbf{1D} & \textbf{2D} & \textbf{3D} & \textbf{5D} & \textbf{10D} & \textbf{50D} & \textbf{100D} & \textbf{200D} \\
		\hline
		\textbf{Sequential Scan} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
		\textbf{Octree} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
		\textbf{Defragmented Pyramid Tree} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
		\textbf{Batch Pyramid Tree} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
		\hline
	\end{tabular}
	\caption{Execution Time of Structures for Uniform Randomly Generated Points with \texttt{-O3} Compiler Flag}
	\label{tab:perf1-randuniform-o3}
\end{table}
\begin{figure}
	\centering
	\includegraphics[scale=0.8]{../results/end_of_iteration1/all_insert_randuniform.pdf}
	\caption{\texttt{insert} Performance on Randomly Generated Uniformly Distributed Datasets}
	\label{fig:perf-1-allinsert}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.8]{../results/end_of_iteration1/all_pquery_randuniform.pdf}
	\caption{Point Query Performance on Randomly Generated Uniformly Distributed Datasets}
	\label{fig:perf-1-allpquery}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.8]{../results/end_of_iteration1/all_delete_randuniform.pdf}
	\caption{\texttt{delete} Performance on Randomly Generated Uniformly Distributed Datasets}
	\label{fig:perf-1-alldelete}
\end{figure}

\subsection{Evaluation}

TODO: evaluate results in previous section

TODO state what was decided to do for next iteration (and why)
