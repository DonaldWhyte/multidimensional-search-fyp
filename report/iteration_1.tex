\section{Iteration \#1 -- Hash-Based Structures}
\label{sec:iteration1}

This iteration deals with the low-level implementation details of the hash-based structures covered in the project. Different optimisation techniques are applied to the structure and multiple implementations of the structure are analysed to determine which is the fastest.

\subsection{Initial Hash Structure Implementation}

The Pyramid Tree, Pseudo-Pyramid Tree and Bit Hash can all be seen as hashing functions, where the one-dimensional value acts as the hash to use when searching a hash table.
An implementation of a generic hash structure, where the hashing function can be varied, will be created to implement all of these implementations. The structure stores all the points in a single array, which hashes each point to an integer representation that acts as the key to a bucket stored in a hash map (specifically \texttt{boost::unordered\_map}, part of the Boost\footnote{\url{http://www.boost.org/}} library). A bucket is an array that contains indices to points in the large array.

To determine if a point $p$ is stored in the structure, $p$ is first hashed into its one-dimensional representation. The corresponding bucket is then sequentially scanned until the point is found or the end of the bucket is reached. To reduce the number of floating point comparisons, especially for large $d$, the \textit{sums} of each point are stored when they are inserted. This way, a $O(d)$ point comparison needs to be made if the $O(1)$ point sum comparison passes.

To delete a point $p$, the point is first hashed and the bucket containing the point is found. The index in the bucket pointing to $p$ is removed, but the actual point itself is not removed from the point array. In other words, the memory is never released until the whole structure is deleted. This makes the structure useful for batch computation because it can be discarded straight after a task, releasing all allocated memory then. However, if the structure is used as part of a long-running process then this is not suitable because there is the potential to run out of memory.  One of the core assumptions of this project is that data may be dynamic, meaning points may be inserted and deleted frequently. For this reason, another implementation of \texttt{delete} which releases memory has been developed.

The \textbf{Rebuild Hash Structure} uses a different strategy for releasing memory for unused points. When a point is removed, the index of the element storing the point is marked. Once $R$ elements are marked, a rebuild procedure is performed. The entire hash structure is rebuilt by first clearing the structure and then inserting all the points \textit{not} marked for deletion. $n - R$ points will be re-inserted and insertion in the worst case is $O(n)$, meaning the worst case complexity of \texttt{delete} is $O((n - R)n)$. The larger $R$ is, the less often the rebuild procedure executions, but a larger amount of allocated memory goes unused at a time.

\subsection{Bucket Variant}

The index-based variants require the CPU to fetch two elements from main memory for each point in a bucket -- the index of a point and the point itself. This also results in more random accesses in the single point array, potentially causing more cache misses, because a bucket's indices may point to distant parts of the large point array. Furthermore, having a large point array makes \texttt{delete} operations difficult to perform cheaply.

The Bucket Pseudo-Pyramid Tree implementation does not use a single array to store the points. Instead of buckets containing an array of point indices, it has an array of actual points. The goal of this variant is to increase \textbf{cache coherency} when searching a bucket, since the point array can be searched sequentially and only one memory read is required. No cleanup procedure is necessary because the memory for a point is released immediately after it's removed, by simply erasing it from the corresponding bucket's array (which is much smaller than an array containing \textit{all} the points). However, \texttt{delete} is still an $O(n)$ operation since the worst case is when a single bucket stores all $n$ points.

The order the points are stored in a bucket do not matter, the C++ \textit{erase-remove} idiom has been used to delete elements from the bucket arrays. This idiom swaps the element to delete with the last element in the array, removing the desired element when it's at the end of the array. This means there is no need to move any elements in the array to fill the gap created by removing an element, since the element removed is always at the end of the array.

\subsection{Splay Tree Variant}

Another implementation of the Pseudo-Pyramid Tree, which does not use a hash map as the underlying one-dimensional index structure, was developed. Instead, the implementation uses a a splay tree. The splay tree is a self-adjusting variant of the binary search tree that uses a \textit{splaying} operation (a heuristic) to allow faster access to recently accessed elements. \cite{splay-tree}. The splaying operation achieves this by performing a series of tree rotations that move a given node up to the root of the tree. Through amortised analysis and empirical experiments, it has been shown splay trees can be more efficient than standard binary trees for a series of non-random operations \cite{splay-tree}, despite the asymptotic worst case bound being worse than binary search trees.

This implementation shall be called the \textbf{Splay Pseudo-Pyramid Tree}. Nodes in the Splay Pseudo-Pyramid Tree correspond to individual buckets in the Bucket Pseudo-Pyramid Tree, meaning each node can store multiple points. Since the splay tree is implemented as a collection of heap-allocated nodes with pointers to link them, deletions are cheap as a low amount of memory needs to be de-allocated per \texttt{delete} operation. The aim is that this, combined with the self-adjusting nature of the splay tree, will produce a Pseudo-Pyramid Tree implementation that is more efficient for non-random operations used in real applications.

\subsection{Fastest Implementation}

TODO

\subsection{Impact of Cache Misses}

These results show storing separate point arrays for each bucket, instead of using one large array to store all the points, increases performance. Both the Bucket and Splay Pseudo-Pyramid Tree implementations provide faster \texttt{insert} and point query operations than the index-based rebuild implementation. As expected, this is due to an increased cache hit rate. Table \ref{tab:perf1-cache-hit-rate} displays the cache miss rate when \textit{inserting} 10,000 points into each Pseudo-Pyramid Tree implementation. Notice how the Rebuild Pseudo-Pyramid Tree, which stores indices in each bucket, has a greater cache miss rate. 

\begin{table}
	\centering
	\begin{tabular}{|l|l|}
		\hline
		\textbf{Structure} & \textbf{Cache Miss Rate (\%) (2 dp)} \\
		\hline
		Rebuild Hash Structure & 4.65 \\
		Bucket Hash Structure & 0.24 \\
		Splay Hash Structure & 0.59 \\
		\hline
	\end{tabular}
	\caption{Cache Hit Rate for \texttt{insert} Operations with Pseudo-Pyramid Variants (200D Randomly Uniform Dataset, 10,000 operations each)}
	\label{tab:perf1-cache-hit-rate}
\end{table}

The differences in speed between the bucket and splay tree implementations is small, but the Bucket Hash Structure slightly outperforms the Splay Tree with most datasets. Again, this may be due to having a lower cache miss rate. 

\subsection{SSE Optimisation}

Since optimising the hashing function resulted in a massive speed increase, it was decided that the function would be parallelised using SSE. Considering point equality is used throughout all the index structures and will be executed many times if there are large buckets in the Pseudo-Pyramid Tree, it is worth optimising to see if there is any major speed-up. Point equality, like the hashing function, is an $O(d)$ operation. In both operations, there is loop which iterates once for each dimension, where each iteration is independent of the others. If 32-bit floating point numbers are used, then four dimensions can be processed at once using 128 bit SSE registers. Since each operation does not spend their entire time hashing or comparing points, it is not expected that a speedup of four can be achieved.

Table \ref{tab:pseudo-pyramid-sse} shows the execution times of the Pseudo-Pyramid Tree with and without SSE optimisation for the hash function and point equality. Across all three operations, the speedup averages to approximately $1.97$ when there are 200 dimensions. Note that if the number of dimensions is less than four, there is little benefit using the 128-bit SSE registers, so the structure uses the sequential hashing function and point equality check.

\begin{table}
	\centering
	\begin{tabular}{|l|l|l|}
		\hline
		\textbf{Operation} & \textbf{Without SSE} & \textbf{With SSE} \\
		\hline
		Insert & 0.092386 & 0.027601 \\
		Delete & 0.035891 & 0.012370 \\
		Point Query & 0.026402 & 0.007745 \\
		\hline
	\end{tabular}
	\caption{Total Execution Time (in seconds) of Rebuild Index Pseudo-Pyramid Tree With and Without SSE Optimisation (10,000 10D Random Points)}
	\label{tab:pseudo-pyramid-sse}
\end{table}

\subsection{Summary}

TODO: summarise which is fastest and how it will be used as basis for all hash-based structures tried