\chapter{Methodology}
\label{chap:methodology}
\centerline{\rule{149mm}{.02in}}
\vspace{2cm}

This section gives information on how the project will be tackled, describing the schedule (plus any changes that have made since its initial creation), tools and technologies that will be used throughout the project.

\section{Schedule}
\label{sec:schedule}

The original schedule was devised near the end of the first week of the project, on 31/01/14. The schedule was broken down into the individual tasks required to complete the defined milestones. These tasks were then grouped into different \textbf{phases}, which ran sequentially with some in parallel. Milestones were associated with these phases, each corresponding to the completion of some deliverable.

The phases of the project and their milestones are:
\begin{enumerate}
	\item \textbf{Project Definition}
	\begin{itemize}
		\item \textbf{Project Outline Defined} -- outline of project's aims and objects is defined 
	\end{itemize}
	\item \textbf{Literature Review and Data Collection}
	\begin{itemize}	
		\item \textbf{Literature Review Complete} -- a literature review has been produced for the field of multi-dimensional search
		\item \textbf{Test Data Collected} -- any non-synthetic external test data sets have been decided and collected
	\end{itemize}
	\item \textbf{Mid-project Presentation and Report}
	\begin{itemize}	
		\item \textbf{Mid-project Presentation Delivered} -- preparation and delivery of mid-project presentation performed to relevant research group
		\item \textbf{Mid-project Report Finished} --  mid-project report submitted
	\end{itemize}	
	\item \textbf{Design and Implementation} -- iterative process that involves designing, implementing and optimising index structures as well as evaluating them to determine which perform the best
	\begin{itemize}
		\item \textbf{Software Deliverables Finished} -- final, optimised implementations of the index structures have been produced, which are ready for a final evaluation
	\end{itemize}
	\item \textbf{Final Report Write-up}
	\begin{itemize}
		\item \textbf{Final Report Finished} -- write-up of the final report, the core deliverable of the project, is submitted
	\end{itemize}
	\item \textbf{Student Symposium}
	\begin{itemize}
		\item \textbf{Final Presentation Delivered} -- preparation and delivery of final project presentation as part of the School's Student Symposium	
	\end{itemize}
\end{enumerate}

Figures \ref{fig:revised-schedule} and \ref{fig:revised-milestone-timeline} in Appendic \ref{chap:supp-material} show a Gantt chart of the project phases and a timeline marked with every milestone. The Gantt chart marks the dates each phase starts and ends. Notice how some phases are running in parallel, with one phase being the primary focus and other being a secondary focus where less is spent. The latest completion date of a milestone is where the corresponding milestone resides on the timeline.

\subsection{Iterative Design and Implementation}
\label{sec:iterative-d-and-i}

The performance tests and evaluation of the implementations could produce unexpected results, showing that it may be beneficial to implement an entirely different index structure or use a different technology. Therefore, deciding on a \textit{fixed} set of index structures to implement and their technologies before starting the implementations at all would be unwise. With such an approach, there is no way to go backwards and revision the project plan if performance tests highlight a poor index structure or technology.

A decision has been made on a \textit{single, initial} index structure to implement. This will be evaluated and based on that evaluation, it will be optimised or it will be discarded in favour of another index structure. This will be repeated in iterations, where each iteration contains the following sub-phases:
\begin{enumerate}
	\item \textbf{Design} -- plan exactly what needs to be done in the iteration and the architectural design of the system/implementation
	\item \textbf{Build} -- implement an index structure or perform one or more optimisations
	\item \textbf{Test} -- perform correctness tests on index structure to ensure it (still) works
	\item \textbf{Performance Analysis} -- perform performance analysis on index structure developed/optimised
	\item \textbf{Evaluation} -- evaluate the produced results and use it to decide what to implement or optimise in the next iteration
\end{enumerate}
When enough iterations have passed or there is no time left to spend on the Design and Implementation phase, the iterations will stop, with the evaluation of the optimised structure(s) in last phase being the final evaluation that is used in the Final Report Write-up phase. This iterative approach is illustrated in the full project process diagram shown in Figure \ref{fig:full-project-process} in Appendix \ref{chap:supp-material}.

\subsection{Original Plan}

The plan has changed since its initial conception. The original plan stated that the initial, unoptimised implementations of the index structures should be finished before the mid-project presentation or report. The idea behind this decision was that having implementations of index structures finished before the presentation, an initial evaluation of the index structures could be performed. The results from this evaluation could then used in the presentation and report as justification for project decisions. However, due to the scope of the research field, the literature take one more week than expected. This meant that there was little time between the end of the literature review and the start of the mid-project presentation and report.

Furthermore, additional time was required to become fully informed about the field of multi-dimensional search and the nature of the data that will be used for evaluation. This knowledge informs the decisions on which index structures to implement, so it was felt that rushing into an initial implementation may result in a poor decision being made on which structures to implement. Therefore, any implementation was pushed back until after the submission of the mid-project report. By doing this, there was more time to consolidate the research findings and make a more informed decision on the index structure(s) to implement.

For completeness, the Gantt chart and milestone timeline for the original plan has been provided in Appendix \ref{chap:supp-material}, in Figures \ref{fig:initial-schedule} and \ref{fig:initial-milestone-timeline}.

\section{Technology}

This section compares some of the potential technologies to use when implementing the index structures and analyse their performance. Justifications are given for the chosen technologies, referring to the project's goals and the experience of the project developer.

\subsection{Programming Language}

There exist many programming languages, all developed for specific purposes. Three programming languages have been considered for this project, with each having different properties. This section will describe these languages, discuss their differences and state which will be used for this project and why.

\textbf{Python} is a high-level interpreted language built for general-purpose computing, which has a large standard library and many third-party libraries \cite{python}. \textbf{C++} is a middle-level, compiled systems programming language, combining low-level features (e.g. manual memory management) and high-level features (e.g. object-orientated programming) \cite{cpp}. C++ applications are compiled straight to the native machine's CPU instruction set, meaning less time is spent translating the code to instructions the hardware can directly execute. \textbf{Haskell} is a purely functional general-purpose programming language which compiles to a native executable, similar to C++ \cite{haskell}. Being purely functional means that applications written in Haskell have no mutable state. This is unlike Python and C++, whose applications have mutable state (since both languages are imperative).

The following aspects have been considered when deciding which language to use:
\begin{itemize}
	\item \textbf{Performance} -- how fast the final application can run. This is based on a number of factors, such as how many intermediary layers there are between the code and the physical machine. Higher-level languages require the computer to do more work, as it has to convert the application's instructions into CPU instructions that are executed directly on the processor.
	\item \textbf{Ease/Speed of Development} -- this encompasses multiple aspects of a language. In order to develop applications quickly, the language must have a mature tool set, large amounts of documentation and support, be easy to understand and require little boilerplate code (so less time is required to write the code). This makes it easier for the developer to write the application, increasing the speed it can be developed.
	\item \textbf{Portability} -- can an application written in a given language execute on many supported platforms or just one? Do multiple versions of the application have to be written or compiled for each platform?
\end{itemize}
 
Executing a Python statement often has more overhead than it would for C++ or Haskell. This is because Python is a high-level, interpreted language, where statements are compiled into bytecode at runtime which is then run on a virtual machine (which translates the bytecode to native assembly instructions). Therefore, many Python applications run slower than C++ or Haskell, which pre-compile applications to native CPU instructions. However, due to the large amount of experience I have in Python, its large standard library and the higher number of abstractions, Python would most likely result in the fastest development time. 

Haskell's pure functional nature makes it fundamentally different than most popular languages and I also have little experience writing programs in a purely functional style. It is predicted this will increase the time it takes to develop the structures, as there is more overhead in learning about functional programming. However, if it is decided that the index structures will be parallelised, then the lack of state and built-in support for parallelisation \cite{parallel-haskell} would make Haskell a powerful choice.

Despite speed of development being important, the primary aim of the project is the acceleration of search. Haskell can be used to write highly optimised code, especially when implementing parallel algorithms to utilise multiple CPU cores. C++ gives the developer more control over the computation and management of memory, allowing for low-level performance tuning. The trade-off for this control is the added complexity of the language \cite{cpp-hard}, leading to an increased amount of code to write and the decrease in development speed that follows. However, C++ is also a mature language with a large set of tools and resources to aid development. Additionally, I have significantly more experience developing in C++ than Haskell. It is unlikely I would be able to produce well-written, optimised Haskell code to fine-tune performance in such a short time. Therefore, C++ has been chosen as the language to use for developing the initial implementation of the index structure.

\subsection{Why Not C?}

TODO

\subsection{Development Tools}
\label{sec:development-tools}

Various tools will be used throughout the development of the structures. \textbf{CMake} \cite{cmake} will be used to automate the building of the written C++ programs. Using a build automation tool means a Makefile can be automatically generated by writing simpler, higher-level and cross-platform scripts, meaning less time is spent focused on build scripts.

Unit tests will be written to ensure the implemented index structures and all the associated algorithms are functioning correctly. A unit test ensures a single unit of the code is exhibiting the desired behaviour. A test is performed in isolation, preventing other code in the application from being executed so it does interfere with the test's results \cite{automated-defect-prevention}. A unit test framework is a suite of code and tools that make writing unit tests easier and faster \cite{unit-test-frameworks}. C++ has many unit testing frameworks, such as CppUnit \cite{cppunit}, NullUnit \cite{nullunit} and Google Test \cite{google-test}. \textbf{Google Test} has been chosen for this project because of the wide feature set and the comprehensive documentation available (at \cite{google-test}).

Version control is a way of tracking changes to textual documents, as well as \textit{who} made the changes \cite{pragmatic-version-control}. A VCS (version control system) will be used to track the changes of the implementation's source code, tests and built automation scripts. Despite this project only having a single developer, there are multiple reasons it has been decided to manage the source code using a VCS. Firstly, it allows the developer to easily keep a log of the changes made to any file and \textit{why} those changes were made. One can also revert source files to prior versions if bugs are found or previously deleted code is required again, Finally, using a VCS means there will be multiple copies of the source code, which can be used as backups to mitigate the damage caused by data loss. The distributed VCS \textbf{Git} \cite{git} will be used for this project, due to the developer having prior experience in the tool, meaning less time is taken from implementation to learn a new tool.

\subsection{Performance Analysis Tools}

In addition to considering the theoretical performance of the chosen algorithms, the implementations' performance will be tested using profiling. Profiling is a way of measuring the performance of a program or system \cite{efficient-cpp} and is used to provide insight into which parts of the code take the longest or use the most memory (i.e. where the performance bottlenecks are). A profiler is a tool which measures some performance metrics of a program. Since the core goal of this project is accelerating multi-dimensional search, being able to measure the performance of the implementations and identify where the performance bottlenecks are is incredibly useful.

To perform the evaluation (see Section \ref{sec:evaluation}), a profiler that can measure heap usage and cache misses will be used. One which can produce call graphs with timings, that measure the flow of execution and how much time is spent in each function, is also desired. Using a profiler that produces little slow down is useful, but not critical, since timings could be scaled to take the extra overhead into consideration. 

Many profilers were considered when choosing one for this project. Intel VTune \cite{intel-vtune} is feature-rich profiler for Intel-based machines, but it is proprietary, so it will not be used for this project. Valgrind \cite{valgrind}, Profiny \cite{profiny} and gperftools \cite{gperftools} are freely available profilers. Out of these, only Valgrind can measure both heap usage and cache misses. gperftools can generate a visualisation of program flow and where the program spends most of its time via a call graph image, with just a single command. gperftools provides a similar feature for heap profiling as well. Therefore, both Valgrind and gperftools will be used for profiling.

\subsection{SSE Optimisation}
\label{sec:sse}

SIMD stands for Single Instruction, Multiple Data and was defined by Flynn as a classification of parallel computing \cite{flynns-taxonomy}. In SIMD, a single instruction is used to operation on multiple data items at the same time. If $p$ is the maximum number of data items that can be operated on in parallel at a time, then in an ideal scenario it is possible increase the speed of a computation by $p$ times. However, it is only suitable for computations where the same operation can be applied to multiple data items independantly, where the order in which those operations complete does not affect the final output.

Streaming SIMD Extensions, or SSE, is a specification of an instruction set that performs SIMD operations for the widely used x86 CPU architecture \cite{sse}, which is the architecture used for the development and test environment of this project. SSE, or specifically SSE2, since that's the latest version supported by the development environment, may be used to accelerate parts of the implementations, which are used frequently, that perform a collection of independant computations.