\chapter{Project Conclusion}
\label{chap:project-conclusion}
\vspace{-0.75cm}
\centerline{\rule{149mm}{.02in}}
\vspace{0.75cm}

This section will discuss the limitations of the project's work and propose future work to support or extend the project's findings. The project's methodology, requirements and final deliverables will then be discussed to measure the project's success.

\section{Limitations}

This project has only worked with three synthetic datasets and three real datasets. Only two of these datasets represent the kind of data this project is targeting, which is data from scientific computation. Using more data from a scientific domain and performing further analysis on their properties may have derived more insight into which index structures are suited to such data.

A large chunk of the Design and Implementation phase was spent focusing on the Pseudo-Pyramid tree and Pyramid Tree before they were found to perform poorly with point queries on the scientific datasets. By the time the limitations of these structures were discovered, there was not enough time to evaluate the other implemented structures in detail. Originally, it was intended that the Multigrid Tree and bucket $kd$-tree (see Appendix \ref{chap:additional-structures}) would be discussed and evaluated alongside the other index structures, but the remaining time did not allow for this.

Exploring these additional index structures, as well as acquiring more scientific datasets to characterise and use for evaluation, would have meant the project could explore the hypotheses made at the end of Chapter \ref{chap:technical-evaluation} in greater detail.

\section{Future Work}

This project ended with a conjecture and several hypotheses. Potential future work includes exploring these in greater detail. This section suggests ways these hypotheses can be explored further.

To further explore the conjecture that most scientific datasets have dense clusters of points in sparse data space, more scientific datasets could be examined in detail. The volume of empty space in these datasets could be measured to derive quantitative measurements of sparsity in scientific datasets. In fact, studying the mathematical challenges of $\mathbb{R}^m \rightarrow \mathbb{R}^d$ where $d > m$, is a whole project in itself.

Exploring Hypothesis 2 would involve implementing and evaluating several adaptive dimension reduction techniques, perhaps using the same test datasets as this project. Examples of techniques to research include iDistance \cite{idistance}, iMinMax($\theta$) and the Multigrid Tree (see Appendix \ref{chap:additional-structures}).

Perhaps the most valuable finding is the superior performance of a tree-based index structure for the target data. Hypothesis 3 states dynamic tree-based structures are more suitable for scientific datasets than dimension reduction techniques for point queries. Verifying this involves implementing several dynamic tree-based structures and evaluating their performance on scientific datasets. Examples of such structures include bucket $kd$-trees and BD-trees \cite{kdtree-v-bdtree}, as well as the KDB-tree, quadtreap and the splay quadtree structures described in Sections \ref{sec:recursive-partition-structures} and \ref{sec:history-sensitive-structures}.

Finally, embedding, distance-based or parallel structures (all briefly mentioned in Chapter \ref{chap:background_research}) are avenues to explore. Based on the literature review, little research has been done on the suitability of these structure types for point queries on dynamic high-dimensional data.

\section{Evaluation of Methodology}

The project and evaluation methodology will be evaluated in this section. The majority of the project's schedule was sequential, having one major task following another. An exception to this was the Design and Implementation phase, which was iterative. There were multiple iterations of the same sub-process, which encompassed design, implementation and evaluation. 

It is felt that this hybrid approach worked well. At the start of the project, the author had almost no knowledge about multi-dimensional search. It required several weeks of background research just to determine the scope and objectives of the project. Synthesising this research into a mid-project report and mid-project presentation took a significant amount of time. Each of these tasks were dependent on the tasks before. Therefore, it made sense to have the initial part of the project serial.

Implementing and testing index structures was the most exploratory part of the project, which required flexibility. Making the Design and Implementation phase iterative provided this flexibility.

The evaluation at the end of each iteration allowed one to gather insight into the implemented structures' performance. After the first two iterations, it was found that the Pyramid Tree had poor performance with the target datasets, so the next iteration turned to entirely different kind of structure. This shows planning everything that should be implemented in advance would be a waste, since new findings would have quickly made these plans irrelevant. It  was also a good decision to have the supervisor meetings at the start of each iteration. It allowed the supervisor to be informed of new findings as soon as possible and offer their advice on what the next course of action should be.

One aspect of the process that could have been improved was the amount of time left for writing the final report. While the schedule left four weeks to write the report, unexpected findings were uncovered. These findings required more time to evaluate and discuss, increasing the time it took to write the final evaluation. Perhaps the schedule should have left another week as a buffer for such situations, which are to be expected in a research project. Overall, combining waterfall and iterative methodologies worked well for this project. It is felt that the correct project methodology was chosen.

The evaluation methodology stated that skewed and clustered synthetic data was tested on the structures. However, these datasets had no negative on the performance of the structures, unlike the real skewed datasets. This was because the synthetic datasets were simply not \textit{skewed enough}. Datasets with higher skew and smaller clusters should have been used. If they were, the Pyramid Tree's weaknesses may have been caught much earlier in the project. Perhaps more time should have been spent working on the evaluation methodology before rushing into performance analysis.

\section{Objectives and Minimum Requirements}

This section discusses if the project have met its objectives. Sections \ref{sec:objectives} and \ref{sec:requirements} list the project's objectives and minimum requirements. The minimum requirements were developed so that meeting them also meets the project's objectives. For brevity, the minimum requirements will be referred to by their numbers.

The literature review present in Chapter \ref{chap:background_research} was a comprehensive survey of the field. The challenges of multi-dimensional search were summarised and most classes of index structures were discussed in some way. A taxonomy illustrating the development of index structures was also produced (see Appendix \ref{chap:supp-material}). Therefore, requirement 1 has been met.

Requirement 2 was met and largely exceeded; a total of nine structures were implemented in the project. Six of these implementations were discussed and analysed in the report. Due to time constraints, the remaining three structures could not be discussed and evaluated in detail. These are described in Appendix \ref{chap:additional-structures}. One of the proposed extensions was developing a new index structure, which was achieved with the Multigrid Tree described in Appendix \ref{chap:additional-structures}.

Requirement 3 was met and exceeded by performing several optimisations across all index structures, with special attention given to base implementation used by all three hash-based structures considered in this project. These optimisations considered cache coherency and SSE parallelisation.

Evaluation was present throughout the Chapters \ref{chap:performance-evaluation} and \ref{chap:technical-evaluation}, meaning Requirement 4 has been met. This requirement was exceeded by performing further evaluation in Chapter \ref{chap:technical-evaluation}, which targeted a specific scientific dataset. This concluded with several hypothesis related to the suitability of different classes of index structure to scientific datasets, exceeding the original requirements of just producing a performance evaluation. Therefore, it is felt requirement 4 has also been exceeded.

All the minimum requirements were met and exceeded to varying degrees. In particular, the amount of optimisations and index structures that were implemented and evaluated was much larger than intended. This was done to ensure the evaluation was as comprehensive as possible within the project time frame.

\section{mdsearch Library}

mdsearch, a C++ library containing implementations of some of the index structures explored in the project, has been made open-source (see Appendix \ref{chap:mdsearch}). The performance of the structures implemented in this library have been measured in two scenarios. The first involves processing the \textit{full} astrophysics dataset. The second uses traces of structure operations from a real application that computes Joint Contour Nets \cite{jcn}. Appendix \ref{chap:mdsearch-application} contains the evaluation of the structures in these scenarios.

\section{Deliverables}

The deliverables described in Section \ref{sec:deliverables} were produced in the following ways:
\begin{enumerate}
	\item Source code of the evaluation framework and all implemented structures, along with documentation, has been submitted alongside this report
	\item Documentation describing what features mdsearch provides and how to use them is available in Appendix \ref{chap:mdsearch}
	\item An evaluation of the index structures was performed as part of Requirement 4
	\item Generated synthetic data can be re-produced using the data generators provided in the source code of Deliverable 1
\end{enumerate}

\section{Conclusion}

To conclude, this project implemented several index structures and evaluated their performance on dynamic high-dimensional data, specifically focusing on scientific datasets. It was found that the Pyramid Tree and a similar structure, the Pseudo-Pyramid Tree, consistently gave poor point query performance with scientific datasets. A well-established structure, the point $kd$-tree, outperformed these two structures by a large margin. An evaluation of these structures' behaviour with the astrophysics dataset was performed, in which some conjectures and hypotheses were derived regarding the suitability of different classes of index structures for dynamic scientific datasets. Future work has been proposed to verify these hypotheses and explore the discussed issues in greater detail.

The overall aim of the project was to implement one or more index structures and evaluate their performance with respect to high-dimensional datasets. Using the astrophysics dataset as a test case, the evaluation went into much greater detail than initially expected. A greater number of index structures and optimisations were implemented than planned, resulting in a more comprehensive evaluation. This evaluation resulted in a conjecture and several hypotheses being made, which has created a foundation to start future work in this area. Therefore, the aim of the project has been met and the project is considered a success.