\chapter{Chosen Index Structures}
\label{chap:chosen-structures-hypothesis}
\centerline{\rule{149mm}{.02in}}
\vspace{2cm}

This section defines the index structures implemented in this project. The reasons for choosing these structures and initial hypotheses on their performance with high dimensional data will be given.

\section{Pyramid Tree}
\label{sec:pyramid-tree-detail}

As described in Section \ref{sec:high-dimensional-structures}, the pyramid tree reduces multi-dimensional points to one dimension, which can then be used in a one-dimensional index structure. The reason this structure has been chosen is because dimension reduction techniques have been found to perform well for high-dimensional data, compared to tree-based approaches \cite{md-structures-samet}. The original Pyramid-Tree paper showed good performance on uniformly distributed data and a real dataset (with the Extended Pyramid-Technique), when compared to Sequential Scan and the competitive X-tree \cite{pyramid-tree}. There are two fundamental differences between the focus of the paper's analysis and what this project is trying to achieve:
\begin{enumerate}
	\item the paper's analysis is for \textit{range} queries, whereas this project is assessing point queries
	\item the real dataset, ``a large text database extracted from WWW-pages" \cite{pyramid-tree}, contains discrete values, whereas the real datasets considered in this project are continuous, scientific datasets
\end{enumerate}
While the database is mapped to a spatial domain when stored in an index structure, the data may have different properties or distributions than continuous, spatial-based data such as the astrophysics turbulence simulation. Therefore, it was decided that the Pyramid Tree will be implemented to explore if the structure can provide equally good performance with point queries on dynamic scientific datasets.

The reduction technique will now be explained in further detail. The Pyramid tree partitions the data space into $2d$ Pyramids where each pyramid uses a $(d - 1)$ hyperplane for its base and the centre of the data space as its tip. Figure \ref{fig:pyramid-tree-pyramids} shows how the $2d$ pyramids extend from the centre point to the data space's boundaries. Each pyramid is segmented by splitting them along $(d-1)$ hyperplanes parallel to the base of the pyramid. The one-dimensional value of a point, called the \textit{pyramid value}, defines which pyramid it is in and its height in said pyramid. The spatial partition is shown in Figure \ref{fig:pyramid-tree-buckets}, where each pyramid segment has a bucket that stores the points inside that segment.

\begin{figure}
		\begin{center}
			\begin{subfloat}[$2d$ Pyramids in 2D Data Space\label{fig:pyramid-tree-pyramids}]{%
				\includegraphics[scale=0.7]{figures/pyramid_tree_partition.pdf}
			}
			\end{subfloat}~
			\begin{subfloat}[Segmented $2d$ Pyramids, Each Associated with a Bucket\label{fig:pyramid-tree-buckets}] {%
				\includegraphics[scale=0.7]{figures/pyramid_tree_buckets.pdf}
			}
			\end{subfloat}
		\end{center}

		\caption{Pyramid Tree's Decomposition of Underlying Data Space}
		\label{fig:pyramid-tree-partition}
\end{figure}

More formally, the pyramid value $pv_v$ of a point $v$ is given by $pv_v = (i + h_v)$, where $i$ represents the pyramid $v$ is contained in, and $h_v$ is height of $v$ in pyramid $i$. $i$ and $h_v$ are given in Equations \ref{eq:pyramid-value-index} and \ref{eq:pyramid-value-height} respectively, where $MOD$ refers to the modulo operator.
\begin{align}
	i &= \begin{cases}
		j_{max},         & \text{if }v_{j_{max}} < 0.5\\
		j_{max} + d,   & \text{if }v_{j_{max}} \geq 0.5\\
	\end{cases}
	\label{eq:pyramid-value-index}
	\\
	j_{max} &= \left( j \;|\; \forall k \; 0 \leq j,k \leq d, j \neq k: \;\; \lvert 0.5 - v_j \rvert \geq \lvert 0.5 - v_k \rvert \right) \nonumber
\end{align}
\begin{equation}
	h_v = \lvert 0.5 - v_{i \; MOD \; d} \rvert
	\label{eq:pyramid-value-height}
\end{equation}

The following lemma shows that two distinct points can be mapped to the same pyramid value. It follows that multiple points may be stored in the same bucket. As such, bucket size will be a key performance factor for the structure and will be measured alongside execution time.

\begin{proof}[\textbf{Lemma: } For $d \geq 2$, there exist two points $x$ and $y$, such that $x \neq y$, with the same pyramid value]\mbox{}\\*
Let $d$ be the number of dimensions and $x = (x_0, x_1, \dots, x_{d -1})$, $y = (y_0, y_1, \dots, y_{d - 1})$ be two $d$-dimensional points. Without loss of generality, assume $0 \leq x_i \leq 1$ and $0 \leq y_i \leq 1$ for all $i = 1, 2, \dots, d$. Suppose $x_0 = y_0 = 0$, $x_{d - 1} = 0.1$, $y_{d - 1} = 0.2$ and $x_i = y_i = 0.1$ for all $i = 1, \dots, {d - 2}$. This means $x \neq y$. The following holds:
\begin{enumerate}
	\item $\forall k \; 0 \leq k \leq d, k \neq 0: \;\; \lvert 0.5 - x_0 \rvert \geq \lvert 0.5 - x_k \rvert$,
	\item $\forall k \; 0 \leq k \leq d, k \neq 0: \;\; \lvert 0.5 - y_0 \rvert \geq \lvert 0.5 - y_k \rvert$.
\end{enumerate}
Since $x_0 \leq 0.5$ and $y_0 \leq 0.5$, both $x$ and $y$ are mapped to pyramid 0 ($i = 0$). It follows that $h_x = h_y = \lvert 0.5 - v_{0 \; MOD \; d} \rvert = \lvert 0.5 - v_{0} \rvert = \lvert 0.5 - 0 \rvert = 0.5$. $pv_x = pv_y = 0 + 0.5 = 0.5$ and $x \neq y$, meaning two distinct points can have the same Pyramid value.

\end{proof}

\section{Pseudo-Pyramid Tree}

\begin{figure}
	\centering
	\includegraphics[scale=0.85]{figures/pseudo-pyramid_tree_point_boundary_distances.pdf}
	\caption{Computing Distance of Point Along Pseudo-Pyramid Tree Boundary for Each Dimension}
	\label{fig:point-boundary-distance}
\end{figure}

The School of Computing have an implementation of an index structure which is similar to the Pyramid Tree. Like the Pyramid Tree, it reduces $d$-dimensional points to a single dimension, which is used to search for the original point in a one-dimensional search structure. Each 1D key has its own bucket that contains references to the original points which are mapped to it. This index structure will be called the \textbf{Pseudo-Pyramid Tree}, because the reduction technique used is \textit{inspired} by the Pyramid tree, but is not the same.  To gain more insight into the performance of dimension reduction techniques in general, the Pseudo-Pyramid Tree will be implemented.

The Pseudo-Pyramid Tree reduction will now be given. To reduce a point $p$, how far along the boundary the point is in each dimension is determined (Figure \ref{fig:point-boundary-distance} gives an illustration of this). These distances are computed using Equation \ref{eq:point-boundary-distance}, where  $min_i$ and $max_i$ define the minimum and maximum bounds for dimension $i$.

\begin{equation}
	h_i(p) = \frac{p_i - min_i}{max_i - min_i}
	\label{eq:point-boundary-distance}
\end{equation}

Let $B$ be a parameter which controls how likely points will be in the same bucket and let $M = \ceil{B^{\frac{1}{d}}}$. The hashed value $h(p)$ of a point $p$ is then given by Equation \ref{eq:pseudo-pyramid-hash}. The function takes $O(d)$ time to compute because of the summation.

\begin{equation}
	h(p) = \sum_{i = 0}^{d} { \lfloor h_i(p) \times M^{i} \rfloor }
	\label{eq:pseudo-pyramid-hash}
\end{equation}

The coefficient $M$ is used to increase the magnitude of $h_i(p)$ before it is truncated with the floor function. This spaces out the mappings of points, decreasing the likelihood two distinct points will be reduced to the same value (and be stored in the same bucket). Increasing $B$ will increase $M$ because $M$ is a power of $B$. Therefore, $B$ can be used to increase or decrease discrimination between points.

\section{$kd$-tree}
\label{sec:kd-tree-detail}

The $kd$-tree is a widely used structure for both low and high dimensional data. In the literature, there is a lot of discussion as to how and why this structure performs poorly in a high-dimensional setting \cite{highd-nn, search-highd-analysis}. $kd$-trees are typically used for \textit{approximate} queries in higher-dimensional space, because they degenerate to Sequential Scan for exact range and nearest neighbour queries \cite{similarity-searching}. 

Similar to the Pyramid Tree, the focus of the literature on $kd$-trees is typically for range and nearest neighbour queries, and not point queries. Unlike the Pyramid Tree however, dynamic variants of $kd$-trees have been explored much more (e.g. in \cite{bkd-tree, kdb-tree}), with the original paper proposing operations for incremental insertion and removal \cite{kd-tree}. Assessing the suitability of multiple classes of structures provides a more comprehensive evaluation. The $kd$-tree has been chosen because it belongs to a different class of index structure than the other chosen structures, which use dimension reduction.

The structure is a multi-dimensional binary tree, meaning the number of nodes does not increase exponentially with $d$ like the octree. Instead of splitting by all dimensions at each level, $kd$-trees split the data space along a single dimension, called the \textit{cutting dimension}.

The variant of the tree implemented for this project is the point $kd$-tree (Section \ref{sec:recursive-partition-structures}). The cutting dimension at each level is chosen by cycling through the dimensions. If $n$ is a $kd$-tree node, $i$ is the cutting dimension on that node's level and $p$ is the point stored in this node, then:
\begin{enumerate}
	\item Let $q$ be any point in the left subtree rooted at $n$: $p_i > q_i$ holds
	\item Let $q$ be any point in the right subtree rooted at $n$: $p_i \leq q_i$ holds
\end{enumerate}
When inserting or querying a point $p$, the tree is traversed top-down in a similar fashion to a standard binary tree, by comparing $p_i$ to $q_i$, where $q$ is the point stored in the current node and $i$ is the cutting dimension of the current level.

The \texttt{delete} operation used is described in \cite{kdtree-remove}. Relative to \texttt{insert} and point queries, this operation requires more computation because it has to maintain the $kd$-tree invariant. To remove a point $p$, first the node containing $p$ is found using the aforementioned top-down traversal approach. Let $n$ be this node and $i$ be the current level's cutting dimension. If $n$ is a leaf, then the node can simply be deleted. Otherwise, let $n_L$ and $n_R$ be the left and right children of $n$ respectively. 

If $n_R$ exists, a node $m$ containing a point with the \textit{minimum} value for dimension $i$ is found in the sub-tree rooted at $n_R$. The points stored in nodes $n$ and $m$ are swapped and \texttt{delete($p$)} is called recursively on the sub-tree rooted at $n_R$.

If $n_R$ does not exist, node $m$ is found in the sub-tree rooted at $n_L$ instead. In this case, after \texttt{delete($p$)} has been recursively called on the sub-tree rooted at $n_L$, the $i$th value of all points stored in this sub-tree are greater than or equal to the $i$th value of the new point in $n$. Therefore, $n_L$ then becomes the \textit{right} child of $n$ to maintain the $kd$-tree invariant. 

Figure \ref{fig:kd-tree} illustrates the \texttt{insert} and \texttt{delete} operations.

\begin{figure}
	\begin{center}
		\makebox[\textwidth][c]{
		\begin{subfloat}[Inserting Point $(3, 1)$\label{fig:kdtree-insert}]{%
			\includegraphics[scale=0.5]{figures/kdtree_insert.pdf}
		}
		\end{subfloat}~~~~
		\begin{subfloat}[Deleting Point $(0, 4)$\label{fig:kdtree-delete}]{%
			\includegraphics[scale=0.5]{figures/kdtree_delete.pdf}
		}
		\end{subfloat}	  
		}%
	\end{center}

	\caption{$kd$-tree Operations for 2D Dataset (Cutting Dimension Alternates Between X and Y)}
	\label{fig:kd-tree}
\end{figure}


\subsection{Bucket Hash Table}
\label{sec:bucket-hash-table}

% http://stackoverflow.com/questions/7403210/hashing-floating-point-values
% https://svn.boost.org/trac/boost/ticket/4038
% http://programmers.stackexchange.com/questions/63595/0x9e3779b9-golden-number
% http://stackoverflow.com/questions/4948780/magic-number-in-boosthash-combine
% http://burtleburtle.net/bob/hash/doobs.html

TODO: rewrite or remove!!!

If larger bucket sizes mean more point comparisons are performed on average, then it is not unreasonable to expect an average bucket size of 1 to provide very good performance. If bucket size is one and the hashing function is an $O(d)$ operation, then each operation will only take $O(d)$ time, regardless of dataset size.

The Bucket Hash Table is a structure which uses the same underlying implemention as a Bucket Pseudo-Pyramid Tree. However, instead of trying to exploit the spatial properties of points directly to provide good bucket size, a different, more general-purpose hashing function provided in the Boost library is used. Like the other hash-based structures discussed in this section, it is possible for two points to be hashed to the same value. However, from empirical performance tests, it has been shown that the average bucket size is almost always near one (bucket size measurements are provided in the next section), meaning most operations are performed in $O(d)$ time.

A high-level algorithm describing the hashing function is given in Algorithm \ref{alg:point-hashing} in Appendix \ref{chap:supp-material}. This function hashes each individual coordinate (floating point value) and combines them using exclusive-or ($\oplus$) and bitshifting operations. A magic number representing the reciprocal of the golden ratio, $\phi = \frac{1 + \sqrt{5}}{2}$, is used when combining the hash values of individual coordinates. The choice to use the golden ratio was inspired by Jenkins' hash function\cite{hash-combine}, where it is used to ensure consecutive floating point values will be mapped to integers with large distances between them. This increases the likelihood of having points distributed more uniformly across buckets when points are clustered within a small numerical range (like they are in the astrophysics dataset).

One major issue with this approach is the potential for floating-point inaccuracy to give incorrect results. On the controlled performance tests executed in this project, a point is queried using the exact same floating point values for the coordinates as when it was inserted. This means the two points have the same identical bit patterns. 

Suppose the point to query was the output of a more complex computation, where rounding errors may come into play. Even if an equal point conceptually is being stored in the structure, rounding errors may cause the two points to have different bit patterns, potentially resulting in different hashed values. The output point, while being stored in the structure, will appear as if it is not. This is a common issue when using floating point values in hashing functions.

Therefore, the Bucket Hash Table may be unreliable for certain applications, especially ones where the input points are the result of computations involving many arithmetic operations.

\section{Main Hypothesis}
\label{sec:main-hypothesis}

Since there has been no published evaluations of the Pseudo-Pyramid Tree, no hypotheses will be made regarding the performance of the structure. It is suspected that the Pseudo-Pyramid Tree will perform well on high-dimensional data, because it is a hash-based method, but little is currently known about how well the structure's hashing function performs, so there is a little basis for such suspicion. Before starting implementation, the following hypothesis regarding the Pyramid Tree and $kd$-tree was devised:

\paragraph{\textbf{HYPOTHESIS:}} Pyramid Tree will be faster than the baselines and $kd$-trees on all evaluation datasets containing high-dimensional data ($\geq 10$ dimensions).

\paragraph{}

This hypothesis was based on the reported performance of the Pyramid Tree and $kd$-tree in a high-dimensional setting in the literature, as discussed in the previous sections. After the implementation phase, the hypothesis will be revisited to determine if it still holds, and \textit{why} it does or does not hold will be explored.